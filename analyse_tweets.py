# -*- coding: utf-8 -*-
"""Analyse_tweets.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eVV8ng7zqvNWU735JuvS3neT6QJ2GNVl

# **TP Textmining** 
#### *Etude port√©e sur les tweets de politiciens fran√ßais*

*05-02-2021*

Les objectifs: 
- Travailler sur du texte fran√ßais.
- Analyser les donn√©es 
- Preprocessing des donn√©es.
- D√©couvrir de nouveaux outils : scattertext.
- Pr√©dire qui a post√© un tweet.

## **1. Installation des packages**
"""

!pip install scattertext
!pip install spacy
!pip install nltk
!pip install termcolor

!python -m spacy download fr_core_news_md

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import time
import datetime


# Modules de traitement du texte
import spacy
import fr_core_news_md
import nltk
import re
from termcolor import colored

# Modules pour le wordcloud
from PIL import Image
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

# Module pour scattertext
import scattertext as st

# Modules de mod√©lisation
from sklearn.utils.fixes import loguniform
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report

import os
from google.colab import drive
drive.mount('drive/')

os.chdir('drive/My Drive')

# chemin o√π se trouve le jeu de donn√©es (tweets_politics_2022.csv)
# PATH_DATA = 'drive/My Drive'

"""## **2. Prise en main de la base de donn√©es **

Les donn√©es ont √©t√© extraites via l'API tweepy dans un autre notebook. \
Les tweets de certains candidats √† l'√©lection pr√©sidentiels ont √©t√© r√©cup√©r√©s. 

Regarder les variables √† disposition, quelques comptages, s'il y a des donn√©es manquantes, quelques graphiques (?), la sp√©cificit√© des tweets, etc.

#### Import des donn√©es
"""

df_tweets = pd.read_csv('tweets_politics_2022.csv', encoding="utf-8")

df_tweets.shape

df_tweets.head()

"""####  Quelques comptages / graphiques

##### Indicateurs simples sur les variables : 
- Y a't'il des donn√©es manquantes ? 
- combien de tweets de chaque candidat ? 
- dates minimales / maximales des tweets
- Distribution des favoris et des retweets de chaque candidat
"""

def check_missing_values(df):
  print("check for missing values : ")
  print(df.isnull().sum()/len(df))  
  return

check_missing_values(df_tweets)

# Combien de tweets dans la base de donn√©es pour chacun des candidats ? 
df_tweets.groupby("user_id").describe()

# A quelles dates ont √©t√© envoy√©s les premiers / derniers tweets des candidats ? 
df_tweets["created_at"] = pd.to_datetime(df_tweets["created_at"]) 
df_tweets.groupby("user_id").created_at.describe()

df_tweets.groupby(["user_id"])["created_at"].apply(lambda x  : [x.min(), x.max()])

# Quelle est la distribution des favoris et retweets des candidats  ?
df_tweets.groupby("user_id").retweet_count.describe()

df_tweets.groupby("user_id").favorite_count.describe()

"""> On voit que les candidats Emmanuel Macron et Eric Zemmour sont tr√®s suivis sur les r√©seaux

##### R√©partition du nombre de retweets / favoris dans le temps
"""

def visualize_count_favorites(df, userID) : 
  
  ''' Cette fonction permet de visualiser le nombre de favoris et de retweets 
  sur toute la p√©riode pour un user_id donn√© '''

  df_temp = df.loc[df["user_id"] == userID]
  ylabels = ["favorite_count", "retweet_count"]

  print("Repr√©sentation des nombres de retweets et de favoris de chaque tweet de {} par date".format(userID))
  fig = plt.figure(figsize=(13,3))
  fig.subplots_adjust(hspace=0.01,wspace=0.01)

  n_row = len(ylabels)
  n_col = 1
  for count, ylabel in enumerate(ylabels):
      ax = fig.add_subplot(n_row, n_col, count + 1)
      ax.plot(df_temp["created_at"], df_temp[ylabel])
      ax.set_ylabel(ylabel)
  
  plt.show()

visualize_count_favorites(df_tweets, "JeanLuc_Melenchon")
print("\n")
visualize_count_favorites(df_tweets, "Marine_Lepen")

"""- JLM : 2 tweets ont √©t√© plus de 20K fois retweet√©s (alors qu'en moyenne, un tweet de JLM est retweet√© 194 fois) et ont eu donc une grande popularit√© par rapport √† son audience normale. 
- MLP a plut√¥t une audience stable, avec quelques tweets qui ont √©t√© plus retweet√©s (pic √† 4K alors qu'en moyenne un tweet de MLP est retweet√© 432 fois).

##### Taille des tweets par politique 

Est-ce que des candidats font des tweets + ou - longs que d'autres ?
"""

# Calcul d'une variable contenant le nombre de mots de chaque tweets
df_tweets["word_count"] = df_tweets["text"].apply(lambda x: len(x.split(" ")))

# Calcul de la distribution de la variable pour chaque politique
df_tweets.groupby("user_id").word_count.describe()

df_tweets

"""##### Lecture de quelques tweets"""

def print_famous_tweets(userID, nb_favorites) :

  ''' Cette fonction permet de s√©lectionner les tweets qui ont eu le plus de favoris 
  pour un user_id donn√©, et de lire le tweet avec les indicateurs des autres variables de la 
  base de donn√©es  
  '''

  df_sub = df_tweets.loc[(df_tweets.user_id==userID) & (df_tweets.favorite_count > nb_favorites),:]
  for irow in range(df_sub.shape[0]):
      df_row = df_sub.iloc[irow,:]
    
      print(df_row["created_at"])
      print("favorite_count={:6} retweet_count={:6}".format(df_row["favorite_count"],df_row["retweet_count"]))
      print(colored(df_row["text"], 'magenta'))
      print("\n")

# pour comprendre la fonction du dessus
df_tweets.shape[0]

print_famous_tweets("Emmanuel_Macron", 90000)

print_famous_tweets("Eric_Zemmour", 20000)

print_famous_tweets("Marine_Lepen", 10000)

"""> **Question** : Qu'y-a't'il de particulier dans les tweets par rapport √† un texte normal ?

On voit que les tweets ont une syntaxe particul√®re : 
- hashtags 
- liens internet
- emojis

### **Filtres**

- Filtre sur la date pour ne prendre en compte que la campagne √©lectorale (d√©but septembre 2021)
- Filtre sur certains candidats pour que les traitements ne soient pas trop longs
"""

DATE_MIN = "2021-09-01 00:00:00"

df_tweets_temp = df_tweets.loc[df_tweets["created_at"] >= datetime.datetime.strptime(DATE_MIN, "%Y-%m-%d %H:%M:%S")] 

print(f"Taille du dataframe : {len(df_tweets)}")

candidats_select = ["Eric_Zemmour", "Marine_Lepen", "Emmanuel_Macron", "JeanLuc_Melenchon"]
                    
df_tweets_sample = df_tweets_temp.loc[df_tweets_temp.user_id.isin(candidats_select)]

print(f"Taille du dataframe : {len(df_tweets_sample)}")

df_tweets_sample.groupby('user_id').describe()

"""## **3. Preprocessing du texte**

On va prendre en compte les particularit√©s des tweets pour nettoyer le texte. \
On va tester les techniques de preprocessing sur du texte fran√ßais : 
- stopwords
- lemmatisation
- tokenisation

### Nettoyage du texte
Dans cette partie, on nettoie le texte pour enlever les mots qui vont rajouter du bruit √† l'analyse (et ne rien apporter) \
Pour nettoyer le texte : 
- suppression des chiffres
- suppression de certaines expressions gr√¢ce √† des expressions r√©guli√®res
- suppression des stopwords
"""

# on charge le mod√®le fran√ßais de spacy
nlp = fr_core_news_md.load()
print(len(nlp.Defaults.stop_words))

# on peut rajouter des stopwords √† la liste de spacy de cette mani√®re : 
nlp.Defaults.stop_words |= {"avoir", "falloir", "faire", "monsieur", "direct",
                            "interview", "livetweet", "suivez", r"invit√©\w+", r"(cha√Æne )?youtube", "mlp"}
                            
# nombre de stopwords 
len(nlp.Defaults.stop_words)

nlp.Defaults.stop_words

"""> **Conseil** :  Toujours regarder la liste enti√®re de stopwords propos√©s pour enlever certains mots qui seraient utiles dans votre √©tude ou rajouter des stopwords non pr√©sents dans la liste

La cellule ci-dessous donne un exemple d'informations que peut donner Spacy :
"""

doc = nlp("Demain je travaille \\n\\n √† la maison. #fatigu√© @hetik \\n https://test.com")

list_spacy = []
                
for token in doc : 
  list_spacy.append([token.text,
                        token.idx,
                        token.lemma_,
                        token.is_punct,
                        token.is_space,
                        token.is_alpha,
                        token.shape_,
                        token.pos_,
                        token.tag_,
                        token.ent_type_])
  
exemple_spacy = pd.DataFrame(list_spacy, columns=["text", "idx","lemma","is_punct","is_space","is_alpha","shape","pos","tag","ent_type"])
exemple_spacy

"""Expressions r√©guli√®res pour nettoyer le texte """

regexp_link = re.compile(r"http\S+") # suppression des liens
regexp_number = re.compile(r"\d+[h., ]?\d*") # suppression des chiffres
regexp_hashtags = re.compile(r"[@#]\S+\s+")   # suppression des hashtags et @

"""<details>    
<summary>
    <font size="3" color="darkgreen"><b>Aide</b></font>
</summary>
<p>
Lorsque vous cherchez √† cr√©er des expressions r√©guli√®res, vous pouvez vous aider en allant sur ce site : <a href="https://regex101.com/" >regex101.com</a> 
</p> 
"""

test_hashtags = "#Fuck √ßa #ne marche @pas !!"
re.sub(regexp_hashtags, "", test_hashtags)

"""Cr√©ation de la fonction de nettoyage du texte 

Coder plusieurs fonctions :      
- une fonction `clean_text_spacy` qui prend en entr√©e un tweet et utilise spacy pour :     
    - supprimer les ponctuations ; 
    - supprimer les stopwords ; 
    - supprimer les caract√®res de type espace (/n, /t, etc.)
Cette fonction garde les tokens entiers
- une fonction `clean_lemmatize` :     
    - supprimer les ponctuations ; 
    - supprimer les stopwords ; 
    - supprimer les caract√®res de type espace (/n, /t, etc.)
Cette fonction garde non pas les tokens entiers, mais les lemmes. 
- une fonction chapeau `preprocess_tweet` qui : 
  - met les mots en minuscule
  - supprime les mots des expressions r√©guli√®res
  - au choix applique la fonction `clean_text_spacy` ou `clean_lemmatize`

<details>    
<summary>
    <font size="3" color="darkgreen"><b>Aide</b></font>
</summary>
<p>
Lorsque vous utilisez les fonctions de spacy, vous allez potentiellement les tokeniser directement (et r√©cup√©rer une liste au lieu d'un texte). Pour √©viter cela, transformez le r√©sultat de cette mani√®re :    

```
result = " ".join(result)
```

</p>
"""

def clean_txt_spacy(doc):
  txt = [token.text for token in doc if  (not token.is_stop) and 
                                         (not token.is_punct) and 
                                         (not token.is_space)]
  result = " ".join(txt)
  return result

def clean_lemmatize(doc):
  lemmatized_txt = [token.lemma_ for token in doc if  (not token.is_stop) and 
                                                      (not token.is_punct) and 
                                                      (not token.is_space)]
  lemmatized_txt = " ".join(lemmatized_txt)
  return lemmatized_txt

"""<details>    
<summary>
    <font size="3" color="darkgreen"><b>Aide</b></font>
</summary>
<p>
- Utiliser re.sub() pour supprimer les liens, hashtags, chiffres
</p> 
"""

def preprocess_tweet(text, lemmatizing = True):

  '''Fonction permettant de nettoyer le texte. Elle renvoie un string (pas de tokenisation encore)'''
  text_clean = text.lower().encode('utf-8').decode('utf-8')
  
  # Suppression des liens, hashtags et chiffres avec les regexp pr√©c√©dentes
  text_clean = re.sub(regexp_link, "", text_clean)
  text_clean = re.sub(regexp_hashtags, "", text_clean)
  text_clean = re.sub(regexp_number, "", text_clean)

  doc = nlp(text_clean)  
  if lemmatizing : 
    preprocessed_tweet = clean_lemmatize(doc)
  else : 
    preprocessed_tweet = clean_txt_spacy(doc)

  return preprocessed_tweet

# exemple pour tester sa fonction 
tweet_test = "Ils Pensaient se moquer #non, ils m'ont donn√© 1 slogan !üòÑ \n\n- Entretien √† d√©couvrir et partager \n\nhttps://t.co/Yn60Areagu"
preprocess_tweet(tweet_test, lemmatizing=True)

# On peut alors nettoyer nos tweets, et cr√©er une nouvelle colonne, text_preprocess
# cela peut prendre un peu de temps √† tourner
df_tweets_sample["text_preprocess"] = df_tweets_sample["text"].apply(lambda tweet : preprocess_tweet(tweet, lemmatizing=True))

# On regarde le r√©sultat du nettoyage du texte
pd.set_option("max_colwidth", None)
df_tweets_sample[["text", "text_preprocess"]].head(10)

"""> Le preprocess n'est pas encore parfait, on pourrait enlever les verbes avec du pos-tagging ou bien rajouter l'info de pos-tagging apr√®s chaque mot. \
> Supprimer les emojis ou les transformer en texte.

### Tokenisation
On tokenise la colonne de tweets pr√©trait√©s (preprocess)

**TODO** : utiliser le module nltk pour tokeniser un tweet avec la fonction tokenisation
"""

nltk.download('punkt') # n√©cessaire pour la tokenisation

def tokenisation(tweet):
  tweet_tokenized = nltk.word_tokenize(tweet)
  return(tweet_tokenized)

df_tweets_sample["tokens"] = df_tweets_sample["text_preprocess"].apply(lambda tweet : tokenisation(tweet))

df_tweets_sample[["text_preprocess", "tokens"]].head()

"""### Analyse du preprocess

On regarde un peu les r√©sultats du preprocessing : 
- combien y a-t-il de mots distincts pour chacun des deux hommes politiques ? 
- Quels sont les mots les plus utilis√©s par deux candidats de votre choix ? 

Pour cela vous vous aiderez des deux fonctions donn√©es ci-dessous
"""

def create_big_tweet_by_userid(userid, col_text) : 

  ''' Fonction pour mettre tous les tweets de chaque politiciens dans un m√™me text (string) '''
  one_big_tweet = " ".join(df_tweets_sample.loc[df_tweets["user_id"] == userid, col_text])
  
  return one_big_tweet

def get_n_most_common_words(list_words, n) :

  ''' Fonction permettant de donner les n mots les plus fr√©quents d'une liste de mots '''
  freq_words = nltk.FreqDist(list_words)
  print(freq_words.most_common(n))

"""Si on n'utilise pas de preprocessing, quels sont les mots les plus utilis√©s par les 2 politiciens ?"""

# Cr√©er un gros tweet pour chacun des deux politiques (qui est la jointure de l'ensemble de ses tweets)
big_tweet_candidate1 = create_big_tweet_by_userid("Marine_Lepen", "text")
big_tweet_candidate2 = create_big_tweet_by_userid("Emmanuel_Macron", "text")

# Tokeniser le gros tweet de chacun des politiques
tokens_candidate1 = tokenisation(big_tweet_candidate1)
tokens_candidate2 = tokenisation(big_tweet_candidate2)

# Regarder les 10 mots les plus communs pour chacun des politiques
get_n_most_common_words(tokens_candidate1, 10)
get_n_most_common_words(tokens_candidate2, 10)

"""**R√©ponse** : les mots les plus utilis√©s sont des stopwords ou des ponctuations

Sans preprocessing, combien y a-t-il de mots distincts pour chaque politique ?
"""

# la fonction set appliqu√©e sur une liste donne une liste d'√©l√©ments uniques
print("Nombre de mots distincts dans les tweets du candidat 1 : {} ".format(len(set(tokens_candidate1))))
print("Nombre de mots distincts dans les tweets du candidat 2 : {} ".format(len(set(tokens_candidate2))))

"""**R√©ponse** : 

Jean Luc M√©lenchon : 11877 \
Eric Zemmour : 8960 \
Marine Lepen : 8108 \
Emmanuel Macron : 4394

M√™me question avec un preprocessing ?
"""

# Cr√©er un gros tweet pour chacun des deux politiques (qui est la jointure de l'ensemble de ses tweets)
big_tweet_candidate1 = create_big_tweet_by_userid('Marine_Lepen', 'text_preprocess')
big_tweet_candidate2 = create_big_tweet_by_userid('Emmanuel_Macron', 'text_preprocess')

# Tokeniser le gros tweet de chacun des politiques
tokens_candidate1 = tokenisation(big_tweet_candidate1)
tokens_candidate2 = tokenisation(big_tweet_candidate2)

# Regarder les 10 mots les plus communs pour chacun des politiques
get_n_most_common_words(tokens_candidate1, 10)
get_n_most_common_words(tokens_candidate2, 10)

print("Nombre de mots distincts dans les tweets du candidat 1 : {}".format(len(set(tokens_candidate1))))
print("Nombre de mots distincts dans les tweets du candidat 2 : {}".format(len(set(tokens_candidate2))))

"""**R√©ponse** : 

Jean Luc M√©lenchon : 5369 \
Eric Zemmour : 4628   \
Emmanuel Macron :  2765  \
Marine Lepen :  4019

### Nuage de mots

On trace un nuage de mots pour chacun des politiques pour voir ce qui ressort

Faire un nuage de mots pour deux candidats de votre choix avec 30 mots

<details>    
<summary>
    <font size="3" color="darkgreen"><b>Aide</b></font>
</summary>
<p>
<ul>
    <li> transformer l'ensemble des tweets d'un politique en un texte unique </li>
    <li> on peut utiliser la fonction WordCloud </li>
</ul>
</p>
"""

# Faire un texte unique pour les tweets de MLP
def create_wordcloud(text, nb_words):
  wordcloud = WordCloud(max_words=nb_words, background_color="white").generate(text)
  plt.figure()
  plt.imshow(wordcloud, interpolation="bilinear")
  plt.axis("off")
  plt.show()

lemat_candidat1 = " ".join(df_tweets_sample.loc[df_tweets_sample.user_id=="Marine_Lepen", "text_preprocess"])
print("Wordcloud des mots lemmatis√©s de l'ensemble des tweets de Marine Le Pen")
create_wordcloud(lemat_candidat1, 30)

lemat_candidat2 = " ".join(df_tweets_sample.loc[df_tweets_sample.user_id=="Eric_Zemmour", "text_preprocess"])
print("Wordcloud des mots lemmatis√©s de l'ensemble des tweets de Eric_Zemmour")
create_wordcloud(lemat_candidat2, 30)

"""C'est bien beau, mais c'est difficile √† analyser, et surtout √† comparer... \
On va utiliser scattertext pour comparer r√©ellement le vocabulaire des 2 politiques.

## **4. Scattertext**

Gr√¢ce √† Scattertext, on va pouvoir comparer de mani√®re visuelle la distinction de vocabulaire utilis√© par deux candidats de votre choix.

On doit d'abord construire un corpus avec nos donn√©es : 
- donner la variable de cat√©gorie 
- donner la variable du texte

On peut rajouter la partie ```.compact(st.AssociationCompactor(4000))``` pour ne prendre en compte que les 4000 mots les plus importants dans le scattertext.

<details>    
<summary>
    <font size="3" color="darkgreen"><b>Aide</b></font>
</summary>
<p>
<ul>
    <li> Filtrer en gardant les tweets des deux candidats de votre choix </li>
</ul>
</p>
"""

df_sample = df_tweets_sample.loc[df_tweets.user_id.isin(["Eric_Zemmour", "JeanLuc_Melenchon"])]

# on cr√©e un objet corpus pour scattertext
corpus = st.CorpusFromPandas(data_frame = df_sample,
                             category_col = "user_id",
                             text_col = "text_preprocess",
                             nlp = nlp).build().compact(st.AssociationCompactor(4000))

"""Une fois le corpus cr√©√©, on peut cr√©er le html avec le scattertext. 

On utilise la fonction ```st.produce_scattertext_explorer``` en donnant les param√®tres qu'on veut : 
- term_ranker
- term_scorer
- transform 

remplir la fonction en r√©fl√©chissant aux param√®tres que vous voulez tester :
"""

# On cr√©e le html du scattertext
html = st.produce_scattertext_explorer(  corpus
                                       , category                  = 'Eric_Zemmour'
                                       , category_name             = 'Eric Zemmour'
                                       , not_category_name         = 'Jean Luc Melenchon'
                                       , minimum_term_frequency    = 10
                                       , pmi_threshold_coefficient = 1
                                       , term_ranker               = st.AbsoluteFrequencyRanker
                                       , transform                 = st.Scalers.dense_rank #st.Scalers.log_scale_standardize pour le ScaledFscore
                                       , term_scorer               = st.RankDifference() 
#on peut √©galemet tester le term_scorer ScaledFscore : st.ScaledFScorePresets(beta=1, one_to_neg_one=True)
                                       , width_in_pixels           = 1000
                                       )

# On enregistre le html
open("drive/My Drive/tweets_visualisation.html", 'wb').write(html.encode('utf-8'))

Regarder le r√©sultat (il apparaitra dans le drive) en t√©l√©chargeant le html (cela peut prendre un petit moment avant de s'afficher correctement).

Analyse du graphique :
On peut voir :
- les mots "stopwords" apparaitre en haut √† droite : 
  - des verbes / des mots balises
  - des mots tr√®s utilis√©s dans le langage politique ("France", "politique", "peuple")
- En bas √† droite, il y a les mots associ√©s √† Jean-Luc M√©lenchon : 
  - "retraite", "programme", "populaire", "commun", "humain"
- En haut √† gauche, il y a les mots associ√©s √† Eric Zemmour : 
  - "Emmanuel Macron", "enfant", "immigration", "√©tranger", "rural", "civilisation"

## **5. Mod√©lisation**

On souhaite pr√©dire si un tweet provient du compte de Marine Le Pen, de Jean Luc M√©lenchon, d'Eric Zemmour ou d'Emmanuel Macron. Pour cela, on a besoin de : 
- Cr√©er un √©chantillon train / dev
- pr√©parer le text (pr√©processing)
- cr√©er des features (plusieurs m√©thodes : bag of words, counts of words, etc.)
- r√©aliser l'algorithme
- √©valuer la performance du mod√®le

### Cr√©ation des √©chantillons 

Cr√©ation d'un √©chantillon train (70% du jeu de donn√©es total) et un √©chantillon test
"""

df_train, df_test, y_train, y_test = train_test_split(df_tweets_sample,
                                                    df_tweets_sample["user_id"], 
                                                    test_size=0.3, 
                                                    random_state=123)

print(f"Nombre de tweets dans l'√©chantillon train : {len(df_train)}")
print(f"Nombre de tweets dans l'√©chantillon test : {len(df_test)}")

# on v√©rifie la r√©partition entre les user 
print(y_train.value_counts(normalize=True))
print("\n")
print(y_test.value_counts(normalize=True))

"""**R√©ponse** : 

Nombre de tweets dans l'√©chantillon train : 4449 \
Nombre de tweets dans l'√©chantillon test : 1907

On a la m√™me r√©partition des candidats entre le train et le test. \
Les donn√©es ne sont pas √©quilibr√©es (Emmanuel Macron a peu de tweets).

### Mod√®le de r√©gression multinomiale sans gridsearch 

- Transformer le texte de df_train et df_test en vecteurs pour le mod√®le
- Utiliser la r√©gression logistique multinomiale sans param√®tre
- Regarder les param√®tres s√©lectionn√©s
- Regarder le score sur l'√©chantillon test

Transformation de df_train pour que ce ne soit plus des tweets, mais des vecteurs gr√¢ce √† <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" >TfidfVectorizer</a>

<details>    
<summary>
    <font size="3" color="darkgreen"><b>Aide</b></font>
</summary>
<p>

La fonction TfidfVectorizer a des param√®tres que vous pouvez choisir : 
<ul>

- Combien de n-grams : vous consid√©rez mot par mot ou bien √©galement des groupes de 2 mots
- max_df : si vous voulez enlever un pourcentage de mots les plus fr√©quents
- min_df : si vous voulez enlever un pourcentage de mots les moins fr√©quents
</p>
"""

vectorizer = TfidfVectorizer(max_df=0.9, min_df=5, ngram_range=(1, 2))
X_train = vectorizer.fit_transform(df_train['text_preprocess'])

"""Cr√©er le mod√®le de r√©gression logistique (OVR) et entrainer le mod√®le sur les donn√©es d'apprentissage"""

# initialiser le mod√®le 
model = LogisticRegression(multi_class="ovr", random_state=54269)

# entrainer le mod√®le avec les donn√©es d'apprentissage
model_default_fit = model.fit(X_train, y_train)

"""NB : le random state permet de figer l'al√©atoire, et de trouver toujours les m√™mes r√©sultats m√™me en faisant tourner le mod√®le plusieurs fois. """

# vous pouvez voir les param√®tres du mod√®le 
model_default_fit.get_params(deep=True)

"""Regarder la performance du mod√®le sur l'√©chantillon train et test (accuracy)"""

# Sur le train
model_default_fit.score(X_train, y_train)

# Sur le test
X_test = vectorizer.transform(df_test['text_preprocess'])
model_default_fit.score(X_test, y_test)

"""**R√©sultat** : On voit que le mod√®le surappend sur l'√©chantillon train, et qu'il y a de grandes diff√©rences de performances entre train et test.

Plus de d√©tails sur ce que donne le mod√®le :
"""

print("le 1er tweet de l'√©chantillon test a √©t√© pr√©dit : ")
print(model_default_fit.predict(X_test[0]))

print(model_default_fit.classes_) # pour conna√Ætre l'ordre des classes / des mod√®les
model_default_fit.predict_proba(X_test[0])

"""Les r√©sultats des 4 mod√®les de r√©gression logistique que scikit learn a fait tourner (car on est en One VS rest). 

On voit donc que le 3e mod√®le qui pr√©dit Jean Luc M√©lenchon VS reste, donne la probabilit√© la plus √©lev√©e (0.55 dans mon cas). Scikit learn pr√©dit donc que le 1er tweet vient du compte de Jean Luc M√©lenchon

### Mise en place de la RandomSearch

On veut mettre en place une randomSearch pour s√©lectionner les meilleurs param√®tres qu'on a choisi d'√©valuer via la m√©thode de cross-validation : 
- on √©tablit d'abord la grille de param√®tres que l'on veut tester
- on effectue la RandomSearch
- on regarde les r√©sultats sur l'√©chantillon test
"""

# Param√®tres √† tester donn√©es, on peut modifier pour tester d'autres param√®tres
dict_params = dict(prep__text_preprocess__max_df=[0.99, 0.95, 0.9],
                   prep__text_preprocess__min_df=[2, 5, 10],
                   clf__C = [1, 20, 50],
                   clf__penalty = ['l2'],
                   clf__multi_class=['ovr', 'multinomial'])

"""Entrainer la Randomsearch avec les param√®tres ci-dessus sur les donn√©es d'apprentissage avec de la cross validation

NB : une pipeline a √©t√© mise en place dans la cellule ci-dessous afin de pouvoir tester √©galement les param√®tres du TFIDF. 
"""

# Entrainer le randomizedsearch 

# Vectorisation de la variable text_preprocess
text_transformer_tfidf =  TfidfVectorizer()
preprocess = ColumnTransformer([("text_preprocess", text_transformer_tfidf, "text_preprocess")], 
                               remainder="drop")

# Type de mod√®le √† tester
model = LogisticRegression(random_state=54269, max_iter=1000)

# Pipeline qui combine le preprocess et le mod√®le
prep_model = Pipeline(steps=[('prep',preprocess),
                             ('clf', model)])

# RANDOMIZED SEARCH
random_search = RandomizedSearchCV( prep_model,
                                   dict_params,
                                   cv=5,  # cross validation de 5 √©chantillons
                                   n_iter=20,
                                   random_state=5439676,
                                   n_jobs=-1,
                                   verbose=1)

best_rd_model = random_search.fit(df_train, y_train)

# Meilleurs param√®tres s√©lectionn√©s par la randomSearch
best_rd_model.best_estimator_

"""Quelle accuracy le meilleur mod√®le a-t'il atteint sur l'√©chantillon train ? """

# R√©sultats du meilleur mod√®le sur l'√©chantillon train 
best_rd_model.best_score_

"""On √©value la performance en calculant l'accuracy du mod√®le s√©lectionn√© par randomsearch sur l'√©chantillon test :


"""

best_rd_model.score(df_test, y_test)

"""### Evaluation de la performance du mod√®le 

On va calculer la matrice de confusion sur l'√©chantillon test

<details>    
<summary>
    <font size="3" color="darkgreen"><b>Aide</b></font>
</summary>
<p>
<ul>
  <li> Pr√©dire les candidats de df_test dans un premier temps </li>
  <li> Vous pouvez utiliser la fonction <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html" >ConfusionMatrixDisplay</a></li>
  
</p>
"""

#matrice de confusion
#confrontation entre Y obs. sur l‚Äô√©ch. test et la pr√©diction
predictions = best_rd_model.predict(df_test)

cm = confusion_matrix(y_test, 
                      predictions, 
                      labels=best_rd_model.classes_)

disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=best_rd_model.classes_)
disp.plot(cmap=plt.cm.Blues,values_format='g',xticks_rotation='vertical')
plt.show()

"""**Question** : Sur l'ensemble des tweets de JLM, combien (pourcentage) ont bien √©t√© pr√©dits JLM ?

**R√©ponse** : 89% des tweets de JLM ont √©t√© pr√©dits JLM par le mod√®le. 

``` 
728/(728+7+77+26) 

```
"""

#On peut aussi retrouver le r√©sultat via cette fonction
print(classification_report(y_test, best_rd_model.predict(df_test)))

"""On voit que le recall (rappel) sur Emmanuel Macron est tr√®s faible (0.45) VS de bons recall pour Jean Luc M√©lenchon ou Eric Zemmour.

### Test sur des nouvelles donn√©es :

Ces quelques tweets ont √©t√© r√©cup√©r√©s apr√®s que la base de donn√©es ait √©t√© r√©cup√©r√©e. Ce sont donc des nouvelles donn√©es que le mod√®le n'a jamais vu.

**Question** : Qui a publi√© ces tweets ?
"""

# Visualisation des tweets √† pr√©dire
df_mystere = pd.read_excel('test_mystere.xlsx')
df_mystere["text"]

# On pr√©pare les donn√©es pour que df_mystere ait la m√™me structure que df_train
df_mystere["text_preprocess"] = df_mystere.text.apply(lambda row : preprocess_tweet(row, lemmatizing=True))
df_mystere["tokens"] = df_mystere.text_preprocess.apply(lambda row : tokenisation(row))

# R√©aliser la pr√©diction avec l'un des deux mod√®les r√©alis√©s
best_rd_model.predict(df_mystere)

"""**R√©ponse attendue** : 

```
array(['Eric_Zemmour', 'Eric_Zemmour', 'JeanLuc_Melenchon',
       'Emmanuel_Macron', 'JeanLuc_Melenchon'], dtype=object)
```
"""